{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85518232-f047-470c-894a-7426c55cebc8",
   "metadata": {},
   "source": [
    "# Transformer Model for Time Series Classification\n",
    "\n",
    "Experimental Notebook\n",
    "\n",
    "November 15 2022\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84612dea-c3a3-41d4-ac51-e93c8d68854c",
   "metadata": {},
   "source": [
    "\n",
    "# Introduction\n",
    "\n",
    "This is the Transformer architecture from Attention Is All You Need, applied to timeseries instead of natural language.\n",
    "\n",
    "This example requires TensorFlow 2.4 or higher."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea2bfa2-e509-47e9-b9c5-3de129614f3b",
   "metadata": {},
   "source": [
    "Sample dataset provided through Keras\n",
    "https://keras.io/examples/timeseries/timeseries_transformer_classification/\n",
    "\n",
    "Load the dataset\n",
    "We are going to use the same dataset and preprocessing as the TimeSeries Classification from Scratch example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ead8b9-c278-4bf3-bc94-43ceb4a89b94",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Build the model\n",
    "Our model processes a tensor of shape (batch size, sequence length, features), where sequence length is the number of time steps and features is each input timeseries.\n",
    "\n",
    "You can replace your classification RNN layers with this one: the inputs are fully compatible!\n",
    "\n",
    "We include residual connections, layer normalization, and dropout. The resulting layer can be stacked multiple times.\n",
    "\n",
    "The projection layers are implemented through keras.layers.Conv1D."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428151ff-549f-46bd-80b8-63b523d0f879",
   "metadata": {},
   "source": [
    "The main part of our model is now complete. We can stack multiple of those transformer_encoder blocks and we can also proceed to add the final Multi-Layer Perceptron classification head. Apart from a stack of Dense layers, we need to reduce the output tensor of the TransformerEncoder part of our model down to a vector of features for each data point in the current batch. A common way to achieve this is to use a pooling layer. For this example, a GlobalAveragePooling1D layer is sufficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca01c24f-ba51-4be7-8c72-e58ef32e130a",
   "metadata": {},
   "source": [
    "# Lets try it for our Landsat time series data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a42f0c0-5dbe-414e-aaf0-9a0a64d01f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pprint\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import glob\n",
    "from functools import reduce\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "#Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "529d1f98-ce77-4c59-986b-0d0340abaa7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-17 11:30:50.892380: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "/home/moeller/lakex055/.conda/envs/tf_gpu/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "# Tensorflow setup.\n",
    "\n",
    "# Tensorflow version 2.4.1\n",
    "import tensorflow as tf\n",
    "print(tf.__version__) \n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Keras setup.\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.layers import Flatten\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Input, Dense, Activation, BatchNormalization, Dropout, Flatten, Lambda, SpatialDropout1D, Concatenate\n",
    "from keras.layers import Conv1D, Conv2D, AveragePooling1D, MaxPooling1D, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.callbacks import Callback, ModelCheckpoint, History, EarlyStopping\n",
    "from keras.models import Model, load_model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed4077d6-0004-4499-b641-ee25629db816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Import from ~/sits folder\n",
    "# Contains readingsits.py file to read and compute spectral features on SITS\n",
    "sys.path.append(\"/panfs/roc/groups/7/moeller/shared/leafy-spurge-demography/temporalCNN/sits\")\n",
    "import readingsits\n",
    "\n",
    "# Import from ~/deeplearning folder\n",
    "# Contains multiple .py files with varying DL architectures \n",
    "sys.path.append(\"/panfs/roc/groups/7/moeller/shared/leafy-spurge-demography/temporalCNN/deeplearning\")\n",
    "\n",
    "import architecture_features\n",
    "import architecture_complexity\n",
    "import architecture_rnn\n",
    "import architecture_regul\n",
    "import architecture_batchsize\n",
    "import architecture_depth\n",
    "import architecture_spectro_temporal\n",
    "import architecture_pooling\n",
    "\n",
    "# Import from ~/outputfiles folder\n",
    "# Contains evaluation.py and save.py files with fucntions to compute summary statistics, write predictions, and create confusion matrices\n",
    "sys.path.append(\"/panfs/roc/groups/7/moeller/shared/leafy-spurge-demography/temporalCNN/outputfiles\")\n",
    "\n",
    "import evaluation\n",
    "import save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a573e73-01f5-4627-9377-1929b9990879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_file:  /panfs/roc/groups/7/moeller/shared/leafy-spurge-demography/datasets_oct22/train_dataset_allyears_full_oct22.csv\n",
      "test_file:  /panfs/roc/groups/7/moeller/shared/leafy-spurge-demography/datasets_oct22/test_dataset_allyears_full_oct22.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set a model results path\n",
    "res_path = '/panfs/roc/groups/7/moeller/shared/leafy-spurge-demography/temporalCNN'\n",
    "\n",
    "# Creating output path if does not exist\n",
    "if not os.path.exists(res_path):\n",
    "  print(\"ResPath DNE\")\n",
    "  os.makedirs(res_path)\n",
    "\n",
    "# Set the path to exported training/testing dataset\n",
    "sits_path = '/panfs/roc/groups/7/moeller/shared/leafy-spurge-demography/datasets_oct22'    \n",
    "    \n",
    "# Set Architecture / Model Run Index (used if running in batch on MSI)\n",
    "noarchi = 0\n",
    "norun = 0\n",
    "feature = \"SB\" #use only spectral bands provided (do not compute new bands, like NDVI, which are already computed)\n",
    "\n",
    "# Parameters to set\n",
    "n_channels = 7 #-- B G NDVI NIR Red SWIR1 SWIR2\n",
    "val_rate = 0.1 # Validation data rate\n",
    "\n",
    "# Evaluated metrics\n",
    "eval_label = ['OA', 'train_loss', 'train_time', 'test_time']\t\n",
    "\t\n",
    "# String variables for the training and testing datasets\n",
    "train_str = 'train_dataset_allyears_full_oct22'\n",
    "test_str = 'test_dataset_allyears_full_oct22'\t\t\t\t\t\n",
    "\n",
    "# Get filenames\n",
    "train_file = sits_path + '/' + train_str + '.csv'\n",
    "test_file = sits_path + '/' + test_str + '.csv'\n",
    "print(\"train_file: \", train_file)\n",
    "print(\"test_file: \", test_file)\n",
    "\t\n",
    "# Output files\t\t\t\n",
    "res_path = res_path + '/Archi' + str(noarchi) + '/'\n",
    "if not os.path.exists(res_path):\n",
    "  os.makedirs(res_path)\n",
    "  print(\"noarchi: \", noarchi)\n",
    "\n",
    "# Create output files to capture model results\n",
    "str_result = feature + '-' + train_str + '-noarchi' + str(noarchi) + '-norun' + str(norun) \n",
    "res_file = res_path + '/resultOA-' + str_result + '.csv'\n",
    "res_mat = np.zeros((len(eval_label),1))\n",
    "traintest_loss_file = res_path + '/trainingHistory-' + str_result + '.csv'\n",
    "conf_file = res_path + '/confMatrix-' + str_result + '.csv'\n",
    "out_model_file = res_path + '/bestmodel-' + str_result + '.h5'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb9bebb6-3ab7-4a75-91b5-d1e1b3f82d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.07200938 0.1070581  0.1344206  ... 0.2114825  0.1468712  0.3813307 ]\n",
      " [0.1770388  0.2509725  0.2587963  ... 0.38377    0.3168075  0.3029786 ]\n",
      " [0.04046    0.0668875  0.095625   ... 0.2135931  0.08785625 0.8973987 ]\n",
      " ...\n",
      " [0.158765   0.1885475  0.227625   ... 0.36491188 0.2431075  0.22428876]\n",
      " [0.0438975  0.0541275  0.0639725  ... 0.23465125 0.10305    0.8873988 ]\n",
      " [0.06847563 0.08204    0.09367938 ... 0.30855063 0.23769687 0.21444525]]\n",
      "(618292, 63)\n",
      "9\n",
      "9\n",
      "[[0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(618292, 10)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Read in SITS training and testing datasets\n",
    "X_train, polygon_ids_train, y_train = readingsits.readSITSData(train_file)\n",
    "X_test,  polygon_ids_test, y_test = readingsits.readSITSData(test_file)\n",
    "print(X_test)  #verify spectral band data looks correct\n",
    "print(X_test.shape) #num_samples, 63 bands (9 timesteps * 7 bands/timestep = 63)\n",
    "\n",
    "\n",
    "# Number of unique classes in y_train and y_test datasets should = 9\n",
    "n_classes_test = len(np.unique(y_test))\n",
    "print(n_classes_test)\n",
    "n_classes_train = len(np.unique(y_train))\n",
    "print(n_classes_train)\n",
    "\n",
    "# heck equal number of classes in training and testing dataset\n",
    "if(n_classes_test != n_classes_train):\n",
    "  print(\"WARNING: different number of classes in train and test\")\n",
    "\n",
    "n_classes = max(n_classes_train, n_classes_test) # 9 classes\n",
    "y_train_one_hot = to_categorical(y_train) # specify number of classes explicity - may need to recode classes sequentially (1-9) to work correctly?\n",
    "y_test_one_hot = to_categorical(y_test)\n",
    "\n",
    "print(y_test_one_hot) #verify one hot encoding was successful\n",
    "print(y_test_one_hot.shape)\n",
    "print(y_test_one_hot[0])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42c5eedf-69fb-4817-a405-fc9ca8e4b9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "9\n",
      "(5008141, 63) (5008141, 10) (556461, 63) (556461, 10) (618292, 63) (618292, 10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#---- Extracting a validation set (if necesary)\n",
    "if val_rate > 0:\n",
    "  #Number of samples to take from Training dataset based on validation rate\n",
    "  val_num_samples = int(math.ceil(X_train.shape[0] * val_rate))\n",
    "\n",
    "  #Select random indices for val_num_samples to select validation set\n",
    "  val_indices = random.sample(range(1, X_train.shape[0]), val_num_samples)\n",
    "  #remove these indices from the training set\n",
    "  train_indices = np.delete(range(1, X_train.shape[0]), val_indices)\n",
    "\n",
    "  #Create training and validation sets \n",
    "  X_val = X_train[val_indices, :]\n",
    "  y_val = y_train[val_indices]\n",
    "  X_train = X_train[train_indices, :]\n",
    "  y_train = y_train[train_indices]\n",
    "\n",
    "  #--- Computing the one-hot encoding (recomputing it for train)\n",
    "  y_train_one_hot = to_categorical(y_train)\n",
    "  y_val_one_hot = to_categorical(y_val)\n",
    "\n",
    "  n_classes_val = len(np.unique(y_val))\n",
    "  print(n_classes_val)\n",
    "  n_classes_train = len(np.unique(y_train))\n",
    "  print(n_classes_train)\n",
    "\n",
    "  #Check equal number of classes in training and testing dataset\n",
    "  if(n_classes_val != n_classes_train):\n",
    "    print(\"WARNING: different number of classes in train and test\")\n",
    "  \n",
    "\n",
    "print(X_train.shape, y_train_one_hot.shape, X_val.shape, y_val_one_hot.shape, X_test.shape, y_test_one_hot.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f737b8f3-befd-4359-a0c7-39d4aef0517b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5008141, 63, 1)\n",
      "(556461, 63, 1)\n",
      "(618292, 63, 1)\n"
     ]
    }
   ],
   "source": [
    "#Format of X and Y training data for input in Transformer model\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734c4ac9-a6bf-4370-9389-486a3e4f5191",
   "metadata": {},
   "source": [
    "# Define model variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad219d7f-0a2d-4744-9271-8fac4c5865e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# Define Model Variables\n",
    "###\n",
    "\n",
    "# Model variables\n",
    "n_epochs = 100\n",
    "batch_size = 5000\n",
    "\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "# inverse of frequency\n",
    "class_weights = {0: 0,\n",
    "                 1: 7.046028630719989,\n",
    "                 2: 3.6421837069230087,\n",
    "                 3: 31.37461158722999,\n",
    "                 4: 0.7614511317372198,\n",
    "                 5: 0.6015453322153169,\n",
    "                 6: 0.3652990948014909,\n",
    "                 7: 0.39487324200412083,\n",
    "                 8: 4.334510403657227,\n",
    "                 9: 13.275284755853498}\n",
    "\n",
    "print(class_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f343d976-135c-4e96-b311-3427c5b55998",
   "metadata": {},
   "source": [
    "# Model Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dce083-c226-43ed-a5e6-5173ef8a988e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Plot Loss and Accuracy Callback\n",
    "class PlotLearning(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.f1 = []\n",
    "        self.val_f1 = []\n",
    "        \n",
    "        self.fig = plt.figure()\n",
    "        \n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        self.logs.append(logs)\n",
    "        self.x.append(self.i)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.f1.append(logs.get('accuracy'))\n",
    "        self.val_f1.append(logs.get('val_accuracy'))\n",
    "        self.i += 1\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        ax1.set_yscale('log')\n",
    "        ax1.plot(self.x, self.losses, label=\"loss\")\n",
    "        ax1.plot(self.x, self.val_losses, label=\"val loss\")\n",
    "        ax1.legend()\n",
    "        \n",
    "        ax2.plot(self.x, self.f1, label=\"Acc\")\n",
    "        ax2.plot(self.x, self.val_f1, label=\"val Acc \")\n",
    "        ax2.legend()\n",
    "        \n",
    "        plt.show();\n",
    "        \n",
    "plot_losses = PlotLearning()\n",
    "\n",
    "\n",
    "# Learning Rate Warmup and Decay Callback\n",
    "def lr_warmup_cosine_decay(global_step,\n",
    "                           warmup_steps,\n",
    "                           hold = 0,\n",
    "                           total_steps=0,\n",
    "                           start_lr=0.0,\n",
    "                           target_lr=1e-3):\n",
    "    # Cosine decay\n",
    "    learning_rate = 0.5 * target_lr * (1 + np.cos(np.pi * (global_step - warmup_steps - hold) / float(total_steps - warmup_steps - hold)))\n",
    "\n",
    "    # Target LR * progress of warmup (=1 at the final warmup step)\n",
    "    warmup_lr = target_lr * (global_step / warmup_steps)\n",
    "\n",
    "    # Choose between `warmup_lr`, `target_lr` and `learning_rate` based on whether `global_step < warmup_steps` and we're still holding.\n",
    "    # i.e. warm up if we're still warming up and use cosine decayed lr otherwise\n",
    "    if hold > 0:\n",
    "        learning_rate = np.where(global_step > warmup_steps + hold,\n",
    "                                 learning_rate, target_lr)\n",
    "    \n",
    "    learning_rate = np.where(global_step < warmup_steps, warmup_lr, learning_rate)\n",
    "    return learning_rate\n",
    "\n",
    "#Plot the learning rate schedule\n",
    "#steps = np.arange(0, 100, 1)\n",
    "#lrs = []\n",
    "\n",
    "#for step in steps:\n",
    "#  lrs.append(lr_warmup_cosine_decay(step, total_steps=len(steps), warmup_steps=10, hold=5))\n",
    "#plt.plot(lrs)\n",
    "\n",
    "\n",
    "class WarmupCosineDecay(keras.callbacks.Callback):\n",
    "    def __init__(self, total_steps=0, warmup_steps=0, start_lr=0.0, target_lr=1e-3, hold=0):\n",
    "\n",
    "        super(WarmupCosineDecay, self).__init__()\n",
    "        self.start_lr = start_lr\n",
    "        self.hold = hold\n",
    "        self.total_steps = total_steps\n",
    "        self.global_step = 0\n",
    "        self.target_lr = target_lr\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.lrs = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        self.global_step = self.global_step + 1\n",
    "        lr = model.optimizer.lr.numpy()\n",
    "        self.lrs.append(lr)\n",
    "\n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        lr = lr_warmup_cosine_decay(global_step=self.global_step,\n",
    "                                    total_steps=self.total_steps,\n",
    "                                    warmup_steps=self.warmup_steps,\n",
    "                                    start_lr=self.start_lr,\n",
    "                                    target_lr=self.target_lr,\n",
    "                                    hold=self.hold)\n",
    "        K.set_value(self.model.optimizer.lr, lr)\n",
    "        \n",
    "        \n",
    "# If already batched\n",
    "# If not batched\n",
    "total_steps = 100\n",
    "# 5% of the steps\n",
    "warmup_steps = int(0.05*total_steps)\n",
    "\n",
    "warmup_callback = WarmupCosineDecay(total_steps=total_steps, \n",
    "                             warmup_steps=warmup_steps,\n",
    "                             hold=int(warmup_steps/2), \n",
    "                             start_lr=0.0, \n",
    "                             target_lr=1e-3)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d0e6f1-5793-44a9-8897-ae4f4857ff4a",
   "metadata": {},
   "source": [
    "# Model Checkpoint Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05424c8-85f4-43be-a56a-4e516d2a46fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10dad27-6179-45dc-b8b6-9c4806808805",
   "metadata": {},
   "source": [
    "# Build the transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ef6777-4804-4b87-ad8c-5644903c56e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Normalization and Attention\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    return x + res\n",
    "\n",
    "\n",
    "def build_model(\n",
    "    input_shape,\n",
    "    head_size,\n",
    "    num_heads,\n",
    "    ff_dim,\n",
    "    num_transformer_blocks,\n",
    "    mlp_units,\n",
    "    dropout=0,\n",
    "    mlp_dropout=0,\n",
    "):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "model = build_model(\n",
    "    input_shape,\n",
    "    head_size=256,\n",
    "    num_heads=4,\n",
    "    ff_dim=4,\n",
    "    num_transformer_blocks=4,\n",
    "    mlp_units=[128],\n",
    "    mlp_dropout=0.1,\n",
    "    dropout=0.1,\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss = \"categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2470ba-db5c-4472-8d64-6652ab6ffd81",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb24e4c5-f001-4d5d-af3a-f8a52b4b5767",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model callbacks\n",
    "#checkpoint = ModelCheckpoint(out_model_file, monitor='val_loss', verbose=1, save_best_only=True, mode='min', restore_best_weights=True)\n",
    "#early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=1, mode='auto')\n",
    "\n",
    "start_train_time = time.time()\n",
    "\n",
    "hist = model.fit(x = X_train,\n",
    "                 y = y_train_one_hot,\n",
    "                 epochs = n_epochs,\n",
    "                 batch_size = batch_size,\n",
    "                 shuffle=True,\n",
    "                 validation_data=(X_val, y_val_one_hot),\n",
    "                 verbose=1,\n",
    "                 callbacks=[warmup_callback],\n",
    "                 class_weight=class_weights)\n",
    "\n",
    "train_time = round(time.time()-start_train_time, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce120a18-2daf-45c6-8a90-54a85734eb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the Trained Model as a .h5 file\n",
    "model.save(r'/panfs/roc/groups/7/moeller/shared/leafy-spurge-demography/temporalCNN/Archi0/draft_transformer_modeL_20epochs_nov152022.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7240f75-8d05-47d0-abf4-37546ee3fa23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-17 11:32:23.527191: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-11-17 11:32:23.529696: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-11-17 11:32:24.540040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:4c:00.0 name: NVIDIA A40 computeCapability: 8.6\n",
      "coreClock: 1.74GHz coreCount: 84 deviceMemorySize: 44.56GiB deviceMemoryBandwidth: 648.29GiB/s\n",
      "2022-11-17 11:32:24.540083: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-11-17 11:32:24.847253: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-11-17 11:32:24.847309: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-11-17 11:32:25.015501: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-11-17 11:32:25.132049: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-11-17 11:32:25.424166: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-11-17 11:32:25.520028: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-11-17 11:32:25.943444: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-11-17 11:32:25.946101: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-11-17 11:32:25.946880: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-17 11:32:25.947742: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-11-17 11:32:25.949080: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:4c:00.0 name: NVIDIA A40 computeCapability: 8.6\n",
      "coreClock: 1.74GHz coreCount: 84 deviceMemorySize: 44.56GiB deviceMemoryBandwidth: 648.29GiB/s\n",
      "2022-11-17 11:32:25.949103: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-11-17 11:32:25.949116: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-11-17 11:32:25.949125: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-11-17 11:32:25.949134: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-11-17 11:32:25.949143: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-11-17 11:32:25.949151: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-11-17 11:32:25.949159: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-11-17 11:32:25.949167: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-11-17 11:32:25.951652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-11-17 11:32:25.951682: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-11-17 11:38:53.699676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-11-17 11:38:53.699751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-11-17 11:38:53.699768: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-11-17 11:38:53.704089: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 42508 MB memory) -> physical GPU (device: 0, name: NVIDIA A40, pci bus id: 0000:4c:00.0, compute capability: 8.6)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load a trained model\n",
    "model = keras.models.load_model(r'/panfs/roc/groups/7/moeller/shared/leafy-spurge-demography/temporalCNN/Archi0/draft_transformer_model_20epochs_nov152022.h5')\n",
    "\n",
    "#model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "638fae7c-6098-4f4b-87fd-65624c7bc25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(618292, 63, 1)\n",
      "(618292,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f677ffc-15a4-4b83-8612-fb13a5b6e5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-17 11:40:01.874441: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-11-17 11:40:01.874927: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2445590000 Hz\n",
      "2022-11-17 11:40:02.178330: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-11-17 11:41:46.759144: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-11-17 11:56:10.291965: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256\n",
      "2022-11-17 11:56:10.367141: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(618292, 10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Predict the model on withheld testing dataset\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "caa9cc9a-2a02-4bb9-9699-dffdd6e76ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(618292, 10)\n",
      "[[2.4843008e-08 2.6338676e-02 1.6415882e-01 2.5248085e-03 9.2164755e-02\n",
      "  5.9947867e-02 1.4070335e-01 3.0800840e-01 1.7370293e-01 3.2450337e-02]\n",
      " [7.7092857e-13 2.9097457e-06 7.8903930e-03 9.2650025e-06 5.4540495e-05\n",
      "  3.5978055e-06 4.7841109e-03 9.8689854e-01 3.5166452e-04 4.9108730e-06]]\n",
      "[7 7]\n",
      "(618292,)\n",
      "[7 7 4 5 6 7 4 4 6 5]\n",
      "[8 7 5 6 6 5 4 4 6 6]\n"
     ]
    }
   ],
   "source": [
    "#Prediction should be 10 classes\n",
    "\n",
    "print(y_pred.shape)\n",
    "print(y_pred[0:2, :])\n",
    "y_pred_argmax =  np.argmax(y_pred, axis=-1)\n",
    "print(y_pred_argmax[0:2])\n",
    "print(y_pred_argmax.shape)\n",
    "\n",
    "\n",
    "print(y_pred_argmax[0:10])\n",
    "print(y_test[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "114719df-e17a-45ba-85dd-a150623c637d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Name                  TP         TN         FP         FN    Accuracy    TPR/Sens/Recall    TNR/Spec    FPR    FNR    Precision    Jaccard      F1\n",
      "--------------------  --------  ---------  ---------  ---------  ----------  -----------------  ----------  -----  -----  -----------  ---------  ------\n",
      "Water                  1094.00  549273.00   59414.00    8511.00        0.89               0.11        0.90   0.10   0.89         0.02       0.02    0.03\n",
      "Developed              1539.00  562882.00   36611.00   17260.00        0.91               0.08        0.94   0.06   0.92         0.04       0.03    0.05\n",
      "BarrenLand              465.00  478371.00  137720.00    1736.00        0.77               0.21        0.78   0.22   0.79         0.00       0.00    0.01\n",
      "Forest                 9114.00  502548.00   25439.00   81191.00        0.83               0.10        0.95   0.05   0.90         0.26       0.08    0.15\n",
      "Shrub/Scrub           14268.00  468098.00   35897.00  100029.00        0.78               0.12        0.93   0.07   0.88         0.28       0.09    0.17\n",
      "Grassland/Herbaceous  31723.00  371310.00   58575.00  156684.00        0.65               0.17        0.86   0.14   0.83         0.35       0.13    0.23\n",
      "Croplands             42203.00  369721.00   74838.00  131530.00        0.67               0.24        0.83   0.17   0.76         0.36       0.17    0.29\n",
      "EmergentWetlands       3030.00  516128.00   86361.00   12773.00        0.84               0.19        0.86   0.14   0.81         0.03       0.03    0.06\n",
      "LeafySpurge               0.00  613149.00       1.00    5142.00        0.99               0.00        1.00   0.00   1.00         0.00       0.00  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4143554/3420075344.py:29: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  F05 = ((1 + beta**2) * precision * TPR_Sens_Recall) / (beta**2 * precision + TPR_Sens_Recall)\n",
      "/tmp/ipykernel_4143554/3420075344.py:31: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  F1 = ((1 + beta**2) * precision * TPR_Sens_Recall) / (beta**2 * precision + TPR_Sens_Recall)\n",
      "/tmp/ipykernel_4143554/3420075344.py:33: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  F2 = ((1 + beta**2) * precision * TPR_Sens_Recall) / (beta**2 * precision + TPR_Sens_Recall)\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True) #suppress scientific notation printing\n",
    "\n",
    "y_pred_argmax = np.argmax(y_pred, axis=-1)\n",
    "#y_pred_flat = y_pred.flatten()\n",
    "#y_pred_flat = y_pred_flat.astype(int)\n",
    "\n",
    "#y_test = y_test.astype(int)    \n",
    "#y_test_flat = y_test.flatten()\n",
    "\n",
    "\n",
    "# Calculate confusion matrix\n",
    "class_names = [\"Water\", \"Developed\", \"BarrenLand\", \"Forest\", \"Shrub/Scrub\", \"Grassland/Herbaceous\", \"Croplands\", \"EmergentWetlands\", \"LeafySpurge\"]\n",
    "class_labels = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "c = multilabel_confusion_matrix(y_test, y_pred_argmax, labels = class_labels)\n",
    "model_output_metrics = []\n",
    "for i in range(len(class_labels)):\n",
    "    tn=c[i, 0, 0]\n",
    "    tp=c[i, 1, 1]\n",
    "    fn=c[i, 1, 0]\n",
    "    fp=c[i, 0, 1]\n",
    "    accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "    TPR_Sens_Recall = tp/(tp+fn)\n",
    "    TNR_Spec = tn/(tn+fp)\n",
    "    FPR = fp/(fp+tn)\n",
    "    FNR = fn/(fn+tp)\n",
    "    precision = tp/(tp+fp)\n",
    "    jaccard = tp/(tp+fp+fn)\n",
    "    beta = 0.5\n",
    "    F05 = ((1 + beta**2) * precision * TPR_Sens_Recall) / (beta**2 * precision + TPR_Sens_Recall)\n",
    "    beta = 1\n",
    "    F1 = ((1 + beta**2) * precision * TPR_Sens_Recall) / (beta**2 * precision + TPR_Sens_Recall)\n",
    "    beta = 2\n",
    "    F2 = ((1 + beta**2) * precision * TPR_Sens_Recall) / (beta**2 * precision + TPR_Sens_Recall)\n",
    "    outputs = [class_names[i], tp, tn, fp, fn, accuracy, TPR_Sens_Recall, TNR_Spec, FPR, FNR, precision, jaccard, F1]\n",
    "    model_output_metrics.append(outputs)\n",
    "\n",
    "# Print and format outputs\n",
    "print(tabulate(model_output_metrics, floatfmt=\".2f\", headers=[\"Class Name\", \"TP\", \"TN\", \"FP\", \"FN\", \"Accuracy\", \"TPR/Sens/Recall\", \"TNR/Spec\", \"FPR\", \"FNR\", \"Precision\", \"Jaccard\", \"F1\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f73367-5439-46f7-aea2-7ae6f2a0ee4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987a3e5a-665c-4d23-9e08-c4084e3f77b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Model Prediction on small TIF raster file\n",
    "\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "import glob\n",
    "\n",
    "# Not used, but might be needed to index across tiles\n",
    "tile_index = 302\n",
    "\n",
    "# Input prediction .tif path\n",
    "image_path = r'/panfs/roc/groups/7/moeller/shared/leafy-spurge-demography/datasets_oct22/rasters_302_2019/'\n",
    "\n",
    "# Output prediction file path\n",
    "outpath = r'/panfs/roc/groups/7/moeller/shared/leafy-spurge-demography/datasets_oct22/raster_predictions_transformer/'\n",
    "\n",
    "# List all .tif files in /rasters folder for prediction\n",
    "tif_image_list = glob.glob(image_path + '*.tif')\n",
    "\n",
    "print(tif_image_list[0:1])\n",
    "\n",
    "# Loop through every tif file for prediction.\n",
    "for t in range(len(tif_image_list)):\n",
    "    \n",
    "    # Open .tif array image with rasterio, read to numpy array\n",
    "    with rasterio.open(tif_image_list[t], 'r') as ds:\n",
    "        arr = ds.read()  # read all raster values\n",
    "\n",
    "    # Define shape of input .tif image\n",
    "    bands, width, height = arr.shape\n",
    "    #print(arr.shape) # (63, 413, 413), we target (618292, 63, 1)\n",
    "    \n",
    "    # Convert Data Type to float32 by division.\n",
    "    arr = arr/10000\n",
    "    \n",
    "    # Reshape .tif array axes for correct format so model can predict. (618292, 63, 1)\n",
    "    arr = np.moveaxis(arr, 0, -1) #move axis to channels last\n",
    "    #print(arr.shape)\n",
    "    #new_arr = arr.reshape(-1, arr.shape[-1]) #reshape to row and column\n",
    "    num_pixels = width*height\n",
    "    new_arr2 = arr.reshape(num_pixels, bands)\n",
    "    #print(new_arr2.shape)\n",
    "    new_arr3 = new_arr2.reshape((new_arr2.shape[0], new_arr2.shape[1], 1))\n",
    "    print(new_arr3.shape)\n",
    "    \n",
    "    p = model.predict(new_arr3) # p is prediction from the DL model\n",
    "    print(p.shape)\n",
    "    # Predict model and reshape to export.\n",
    "    #p = model.predict(new_arr3) # p is prediction from the DL model\n",
    "    pim = p.reshape(width, height, 10) # Dimension of prediction in rows, columns, bands (10 classes)\n",
    "    pim2 = np.moveaxis(pim, 2, 0) # move axis so bands is first\n",
    "\n",
    "    # ArgMax for Segmentation.\n",
    "    pim3 = np.argmax(pim2, axis=0) # take softmax of predictions for segmentation\n",
    "    print(pim3.shape)\n",
    "\n",
    "    # Get the file name (landsat_image_170_t.tif) by splitting input path.\n",
    "    fileout_string = os.path.split(tif_image_list[t])\n",
    "\n",
    "    # Output prediction raster .\n",
    "    out_meta = ds.meta.copy()\n",
    "\n",
    "    # Get Output metadata.\n",
    "    out_meta.update({'driver':'GTiff',\n",
    "                     'width':ds.shape[1],\n",
    "                     'height':ds.shape[0],\n",
    "                     'count':1,\n",
    "                     'dtype':'float64',\n",
    "                     'crs':ds.crs, \n",
    "                     'transform':ds.transform,\n",
    "                     'nodata':0})\n",
    "\n",
    "    # Write predicted raster to file.\n",
    "    with rasterio.open(fp=outpath + \"/prediction_\" + fileout_string[-1], #outputpath_name\n",
    "                 mode='w',**out_meta) as dst:\n",
    "                 dst.write(pim3, 1) # the numer one is the number of bands\n",
    "\n",
    "    print(\"Writing file...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a416e7-00c6-487f-851e-b698785c8fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7804a8e7-d35a-46db-a3de-82cbf5df4897",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predict model and reshape to export.\n",
    "#p = model.predict(new_arr3) # p is prediction from the DL model\n",
    "pim = p.reshape(width, height, 10) # Dimension of prediction in rows, columns, bands (10 classes)\n",
    "pim2 = np.moveaxis(pim, 2, 0) # move axis so bands is first\n",
    "\n",
    "# ArgMax for Segmentation.\n",
    "pim3 = np.argmax(pim2, axis=0) # take softmax of predictions for segmentation\n",
    "print(pim3.shape)\n",
    "\n",
    "# Get the file name (landsat_image_170_t.tif) by splitting input path.\n",
    "fileout_string = os.path.split(tif_image_list[t])\n",
    "\n",
    "# Output prediction raster .\n",
    "out_meta = ds.meta.copy()\n",
    "\n",
    "# Get Output metadata.\n",
    "out_meta.update({'driver':'GTiff',\n",
    "                 'width':ds.shape[1],\n",
    "                 'height':ds.shape[0],\n",
    "                 'count':1,\n",
    "                 'dtype':'float64',\n",
    "                 'crs':ds.crs, \n",
    "                 'transform':ds.transform,\n",
    "                 'nodata':0})\n",
    "\n",
    "# Write predicted raster to file.\n",
    "with rasterio.open(fp=outpath + \"/prediction_\" + fileout_string[-1], #outputpath_name\n",
    "             mode='w',**out_meta) as dst:\n",
    "             dst.write(pim3, 1) # the numer one is the number of bands\n",
    "\n",
    "print(\"Writing file...\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc66c973-c90f-4066-98b6-3b220d2442f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(pim3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59a1125-84de-4757-aecc-031a5ceeec67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu_earthengine",
   "language": "python",
   "name": "tf_gpu_earthengine"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
